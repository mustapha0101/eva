import os
import streamlit as st
from deepeval import evaluate
from deepeval.test_case import LLMTestCase, LLMTestCaseParams
from deepeval.metrics import GEval
import PyPDF2
from docx import Document
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import matplotlib

# --- Force UTF-8 pour les graphiques (√©vite les erreurs avec les accents) ---
matplotlib.rcParams['font.family'] = 'DejaVu Sans'

# --- Configuration de la page ---
st.set_page_config(
    page_title="EVA - √âvaluation des r√©sum√©s",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="expanded",
)

st.markdown("<h1 style='color:#4b77ff;'>EVA - Outil d'√©valuation des r√©sum√©s juridiques</h1>", unsafe_allow_html=True)
st.write("T√©l√©chargez deux fichiers (PDF ou DOCX) : un document original et son r√©sum√©, puis lancez l'√©valuation.")

# --- Sidebar OpenAI ---
st.sidebar.header("‚öôÔ∏è Configuration OpenAI")
openai_api_key = st.sidebar.text_input("Cl√© API OpenAI", type="password")
model_string = st.sidebar.text_input(
    "Mod√®le OpenAI",
    value=os.environ.get("OPENAI_MODEL", "gpt-4o-mini")
)

# V√©rification de la cl√© API
if not openai_api_key:
    st.warning("‚ö†Ô∏è Veuillez entrer votre cl√© OpenAI pour √©valuer le r√©sum√©.")
else:
    os.environ["OPENAI_API_KEY"] = openai_api_key
    os.environ["OPENAI_MODEL"] = model_string

# --- Fonctions pour extraire le texte ---
def extraire_texte_pdf(pdf_file):
    reader = PyPDF2.PdfReader(pdf_file)
    textes = [page.extract_text() for page in reader.pages if page.extract_text()]
    return "\n".join(textes)

def extraire_texte_docx(docx_file):
    doc = Document(docx_file)
    return "\n".join([para.text for para in doc.paragraphs])

def nettoyer_texte(texte):
    return ' '.join(texte.split())

# --- Uploads c√¥te √† c√¥te ---
col1, col2 = st.columns(2)
with col1:
    fichier1 = st.file_uploader("üìÑ Document original", type=["pdf", "docx"])
with col2:
    fichier2 = st.file_uploader("üìù R√©sum√©", type=["pdf", "docx"])

# --- Evaluation ---
if fichier1 and fichier2 and openai_api_key:
    # Extraction
    texte1 = extraire_texte_pdf(fichier1) if fichier1.type == "application/pdf" else extraire_texte_docx(fichier1)
    texte2 = extraire_texte_pdf(fichier2) if fichier2.type == "application/pdf" else extraire_texte_docx(fichier2)

    texte1_nettoye = nettoyer_texte(texte1)
    texte2_nettoye = nettoyer_texte(texte2)

    # Affichage c√¥te √† c√¥te
    st.subheader("üìë Textes compar√©s")
    col1, col2 = st.columns(2)
    with col1:
        st.text_area("Texte original", texte1_nettoye, height=250)
    with col2:
        st.text_area("R√©sum√©", texte2_nettoye, height=250)

    if st.button("üöÄ √âvaluer le r√©sum√©"):
        try:
            # D√©finition des m√©triques
            metrics = [
                GEval(
                    name="Concision",
                    criteria="Le r√©sum√© est-il concis et repr√©sente tous les √©l√©ments cl√©s de la source ? R√©ponds strictement en fran√ßais.",
                    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],
                ),
                GEval(
                    name="Couverture",
                    criteria="Le r√©sum√© couvre-t-il toutes les informations juridiques importantes du texte source ? R√©ponds strictement en fran√ßais.",
                    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],
                ),
                GEval(
                    name="Exactitude",
                    criteria="Le r√©sum√© repr√©sente-t-il fid√®lement le contenu du texte source sans erreurs factuelles ? R√©ponds strictement en fran√ßais.",
                    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],
                ),
                GEval(
                    name="Citations",
                    criteria="S'il y a des articles de loi ou jurisprudences cit√©s dans le texte source, sont-ils identiques dans le r√©sum√© ? R√©ponds strictement en fran√ßais.",
                    evaluation_params=[LLMTestCaseParams.INPUT, LLMTestCaseParams.ACTUAL_OUTPUT],
                )
            ]

            # Cas de test
            cas_de_test = [LLMTestCase(input=texte1_nettoye, actual_output=texte2_nettoye)]

            # √âvaluation
            resultat = evaluate(cas_de_test, metrics=metrics)

            # Traitement des r√©sultats
            if hasattr(resultat, 'test_results') and resultat.test_results:
                test_result = resultat.test_results[0]
                if hasattr(test_result, 'metrics_data') and test_result.metrics_data:
                    donnees = []
                    for m in test_result.metrics_data:
                        donnees.append({
                            'M√©trique': m.name,
                            'Score': getattr(m, 'score', 0),
                            'Seuil': getattr(m, 'threshold', 0.5),
                            'Succ√®s': '‚úÖ Succ√®s' if getattr(m, 'success', False) else '‚ùå √âchec',
                            'Raison': getattr(m, 'reason', 'Pas de justification fournie.')
                        })
                    df = pd.DataFrame(donnees)

                    # R√©sultats tabulaires
                    st.subheader("üìä R√©sultats d'√©valuation")
                    st.dataframe(df, use_container_width=True)

                    # Graphiques c√¥te √† c√¥te
                    col_g1, col_g2 = st.columns(2)

                    # Bar Chart
                    with col_g1:
                        plt.figure(figsize=(6, 5))
                        sns.barplot(data=df, x='M√©trique', y='Score', hue='Succ√®s', dodge=False)
                        plt.axhline(y=0.5, color='r', linestyle='--', linewidth=1.5, label='Seuil')
                        plt.ylim(0, 1)
                        plt.title("Scores par m√©trique")
                        plt.legend()
                        st.pyplot(plt)

                    # Radar Chart
                    with col_g2:
                        categories = df['M√©trique']
                        values = df['Score'].tolist()
                        values += values[:1]  # fermer le radar
                        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
                        angles += angles[:1]

                        fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))
                        ax.plot(angles, values, linewidth=2, linestyle='solid')
                        ax.fill(angles, values, alpha=0.3)
                        ax.set_xticks(angles[:-1])
                        ax.set_xticklabels(categories)
                        ax.set_ylim(0, 1)
                        plt.title("Radar des scores par m√©trique")
                        st.pyplot(fig)

                    # Logs d√©taill√©s dans un accord√©on ferm√©
                    with st.expander("üìú Logs d√©taill√©s de l'√©valuation"):
                        for m in donnees:
                            st.markdown(f"**{m['M√©trique']}** : {m['Raison']}")
                else:
                    st.error("‚ö†Ô∏è Aucune donn√©e de m√©trique g√©n√©r√©e.")
            else:
                st.error("‚ö†Ô∏è Aucun r√©sultat disponible. V√©rifie les fichiers.")

        except Exception as e:
            st.error(f"Erreur lors de l'√©valuation : {e}")
